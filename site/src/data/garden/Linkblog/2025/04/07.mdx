---
name: "Linkblog/2025/04/07"
description: "Minecraft Movie, Best Programmers I Know, Docker AI, Jane Remover 'Revengeseekerz', How does u128 work on a 64-bit processor?, Next.js Deployment Adapters API, Odin area allocators gotchas, leibovitz dithering tool, Integrating Zig & SwiftUI, Thinking Time for game design, AI and the creator's funnel, THE PHOENICIAN SCHEME by Wes Anderson trailer, Tobi on AI at Shopify, Apple replaces rsync with openrsync."
ogImage: "/asset/Screenshot_2025-04-08_at_1.12.30 AM_1744083759827_0.png"
---

[Brandon Orselli - A Minecraft Movie shatters box office records with $301m opening weekend](https://nichegamer.com/a-minecraft-movie-opening-weekend-301m/)

<div class="ml-[calc(1*1rem)] mb-8">
[_Chicken Jockey_](https://minecraft.fandom.com/wiki/Chicken_Jockey).

I saw the movie tonight:

<video controls src='/asset/chicken-jockey_1744081329331_0.mp4' width='960' height='540'></video>

Honestly, as far as video game adaptations go... I think it actually did a pretty good job, it was freaking _corny_, but in a self-referential _aware_ way.

Spotting [DanTDM](https://www.youtube.com/watch?v=ESTmx5zsUE4), the [Technoblade reference](https://timesofindia.indiatimes.com/sports/esports/minecraft/minecraft-movies-hidden-technoblade-tribute-explained/articleshow/120067744.cms), and [Jens](https://old.reddit.com/r/MinecraftLeaks/comments/1jh5825/jeb_jens_bergensten_cameo_spotted_in_the_new_tv/), was also fun.

<div class="w-full h-4"></div>

[An unfinished version of the movie has leaked online as well](https://movieweb.com/a-minecraft-movie-unfinished-workprint-leaks-online/), I _might_ have a copy of it on my computer...

Its _really_ funny.

</div>
[Matthias Endler - The Best Programmers I Know](https://endler.dev/2025/best-programmers/)

<div class="ml-[calc(1*1rem)] mb-8">
> I have met a lot of developers in my life. Lately, I asked myself: “What does it take to be one of the best? What do they all have in common?” [...]

Matthias has a lot of great points here, I myself _attempt_ to put them into play (sometimes).

> **Read the Reference**
>
> If there was one thing that I should have done as a young programmer, it would have been to *read the reference* of the thing I was using. I.e. read the [Apache Webserver Documentation](https://httpd.apache.org/docs/2.4/), the [Python Standard Library](https://docs.python.org/3/library/index.html), or the [TOML spec](https://toml.io/en/v1.0.0).

This 100% times, the amount of times I see beginners reaching for [W3Schools](https://www.w3schools.com/) over [MDN](https://developer.mozilla.org/)...

> **Break Down Problems**
>
> Everyone gets stuck at times. The best know how to get unstuck. They simplify problems until they become digestible. That’s a hard skill to learn and requires a ton of experience. [...]
>
> **Don’t Be Afraid To Get Your Hands Dirty**
>
> The best devs I know read a lot of code and they are not afraid to touch it. They never say “that’s not for me” or “I can’t help you here.” Instead, they just start and learn. Code is just code. [...]
>
> **Never Stop Learning**
>
> Some of the best devs I know are 60+ years old. They can run circles around me. Part of the reason is that they keep learning. [...]

</div>
[Jean-Laurent de Morlhon - Introducing the Beta Launch of Docker’s AI Agent, Transforming Development Experiences](https://www.docker.com/blog/beta-launch-docker-ai-agent/)

<div class="ml-[calc(1*1rem)] mb-8">
Both Docker Desktop _and_ the CLI has AI in it now.

Why?

Because everything needs that now for some reason.

</div>
[Ryan Dombal - Jane Remover Takes Their Place as Hyperpop’s Vengeful Superhero on ‘Revengeseekerz’](https://www.hearingthings.co/jane-remover-revengeseekerz-album-review/)

<div class="ml-[calc(1*1rem)] mb-8">
New Jane Remover is good.

The second track goes hard:

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/7BMSBNctr9IPelr6MFvuRL?utm_source=generator" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

</div>
[Graham King - Underrust: How does u128 work on a 64-bit processor?](https://darkcoding.net/software/underrust-u128/)

<div class="ml-[calc(1*1rem)] mb-8">
> **Developer:** Wise Compiler Crab, I seek to unravel the mysteries of my u128 sword. How can it wield such power on a realm ruled by 64-bit registers?

With with barbed remarks, Graham explains how [`u128`](https://doc.rust-lang.org/std/primitive.u128.html) actually works even though [the plan fell off](https://en.wikipedia.org/wiki/128-bit_computing).

<div class="ml-[calc(2*1rem)] mb-8">
(Yes that was a dumb [9front](https://9front.org/) reference.)

</div>
</div>
[vercel/next.js - RFC: Deployment Adapters API](https://github.com/vercel/next.js/discussions/77740)

<div class="ml-[calc(1*1rem)] mb-8">
> To ensure Next.js can be deployed anywhere, including severless platforms with custom requirements, we are planning to add deployment adapters. Vercel will use the same adapter API as every other partner.

I wonder if this will mean [OpenNext](https://opennext.js.org/) won't be needed anymore, I would _assume_ the OpenNext folks would embrace that maybe, as maybe this is _actually_ an answer from Vercel of how to run it serverless just like they do.

<div class="ml-[calc(2*1rem)] mb-8">
This seems to be the case, CloudFlare has done some releases involving their [`@opennextjs/cloudflare`](https://opennext.js.org/cloudflare) package, but also in [this blog post](https://blog.cloudflare.com/full-stack-development-on-cloudflare-workers/), have mentioned:

> Those using the OpenNext adapter will also be able to easily upgrade to the [recently announced Next.js Deployments API](https://github.com/vercel/next.js/discussions/77740).

_Nice!_.

</div>
I spoke about [Edurado's article on Next.js the other day](/linkblog/2025/03/26), and this was one of his big gripes as someone working on Next.js support at Netlify.

They even reference Netlify directly:

> However, it has been difficult for serverless platforms like Netlify to support deploying Next.js due to their custom requirements. After talking with their team and others, we want to make Next.js easier to maintain for deployment platforms.

_Hopefully_ Edurado's gripes get resolved, but this is at the RFC stage, I feel like most won't trust them before action is taken to _actually_ support this stuff, not just _talk_ about supporting it.

</div>
[Karl Zylinski - Mistakes and cool things to do with arena allocators](https://zylinski.se/posts/dynamic-arrays-and-arenas/)

<div class="ml-[calc(1*1rem)] mb-8">
> When programming in Odin you can use arena allocators. If you use an arena allocator combined with a dynamic array, then there are a couple of pitfalls that may not be apparent at first. Let’s look at what arenas are, how you can run into trouble when naively using them with dynamic arrays and what you can do instead.

As always, Karl is making dope [Odin](https://odin-lang.org/) content again.

<div class="w-full h-4"></div>

Karl also has a video companion to this article as well:

<iframe
    class="my-2"
    width="100%"
    height="400"
    src="https://www.youtube.com/embed/1WnqZPD-qVc"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen
></iframe>

</div>
[Eli Mellen - leibovitz](https://eli.li/leibovitz)

<div class="ml-[calc(1*1rem)] mb-8">
> Folks what that haunt me (positive) on the Fediverse may have seen me [sharing progress shots from this](https://tenforward.social/@eli_oat/114248710757201441), but here I am, and I have made another camera application for the web. [Leibovitz](https://smallandnearlysilent.com/leibovitz/) combines a lot that I learned making my other camera applications into one, hopefully less clunky package.

[Put some images you have into the tool and play around with i](https://smallandnearlysilent.com/leibovitz/)t, its quite fun.

<Image src='/asset/Screenshot_2025-04-08_at_1.12.30 AM_1744083759827_0.png' alt='Screenshot 2025-04-08 at 1.12.30 AM.png' width={1696} height={1450} />

_Look at Peanut, he's so amazing_.

</div>
[Mitchell Hashimoto - Integrating Zig and SwiftUI](https://mitchellh.com/writing/zig-and-swiftui)

<div class="ml-[calc(1*1rem)] mb-8">
> Building a native GUI for a cross-platform application is a decades old problem. Nowadays, most people just *don't* and fallback to using a non-native experience such as Electron instead.
>
> One approach to building a native GUI for a cross-platform application is to write all of the business logic in a cross-platform language (C, Rust, Zig, etc.) and then write the platform-specific GUI code. This is the approach I take with my [my terminal emulator](https://twitter.com/mitchellh/status/1662217955424493570) and it works really well. As of the current date writing this post, 93% of my repository is business logic in Zig and C, and 4% is macOS-specific GUI code in Swift.

I've been using [Ghostty](https://ghostty.org/) for a _while_ now.

<div class="ml-[calc(2*1rem)] mb-8">
I managed to get into the beta a year before release, it was already to the point I had no bugs with it so to me it was simply a dope terminal emulator I felt like I had clout for having access to.

<Image src='/asset/Screenshot_2025-04-08_at_1.18.06 AM_1744084157244_0.png' alt='Screenshot 2025-04-08 at 1.18.06 AM.png' width={788} height={266} />

</div>
The design of the application to me has been interesting, I've used it on both Linux and Mac, so I've used SwiftUI Ghostty, and GTK based Ghostty: both feel _native_ to their platforms.

While I think [Electron](https://www.electronjs.org/) / [Tauri](https://v2.tauri.app/) / [Qt](https://www.qt.io/) / etc. are _good_ choices for most, I do think if you have the time and skill, and _bother_ to learn _the big 3_ (or be like Mitchell and just ditch Windows support so its just the big two sans the big _one_ to you), _why not?_.

I've got a project I think I might actually use this structure for.

I'm _thinking_ Odin for the core of mine, because I'm an Odin enjoyer, SwiftUI for Mac (duh), GTK for Linux, WinForms for Windows.

I think targeting a OpenGL version that works on all 3 would be good for the first version, maybe having a Metal native version like Ghostty has for Mac would be cool, but maybe not worth the extra work.

<div class="ml-[calc(2*1rem)] mb-8">
Or figure out how to work with [SDL3 GPU](https://wiki.libsdl.org/SDL3/CategoryGPU) in this context, _if possible_.

I'm competent enough to be dangerous in this space, my guess is parts of what I'm saying are true while others are misguided.

</div>
</div>
[Charlie Cleveland - Thinking Time for game design](https://www.charliecleveland.com/thinking-time-for-game-design/)

<div class="ml-[calc(1*1rem)] mb-8">
> **Thinking Time Exercise**
>
> Sit somewhere quiet
>
> Hit the bathroom, get some water, etc. first so your body doesn't find an excuse for you to get interrupted.
>
> Write a high-quality question at the top of a blank piece of paper
>
> Don't use a computer or phone. The author uses the same "thinking chair" and has a dedicated journal.
>
> Set a timer for 45-60 minutes
>
> Best to use a [dedicated timer](https://www.amazon.com/dp/B08ZMT5RV4?ref_=ppx_hzsearch_conn_dt_b_fed_asin_title_1&ref=charliecleveland.com) instead of a phone, to avoid getting distracted and to lean into "analog mode".
>
> Write and think about this one problem until the timer finishes
>
> Do this without interruptions - no querying, or web or phone use. The goal is write a lot, without editing. Your goal is ideas and possibilities, not absolute answers.
>
> When you're done, read it over
>
> This might give you answers, or may give you direction for another thinking time session. You may find that your best works shows up later in the session, so make sure to sit through the whole 45-60 minutes (I've found the best ideas come in this extra time in [group working sessions](https://www.abyssal.co/creative-feedback?ref=charliecleveland.com) also).

This sounds good, I'm not sure what sort of questions I'd personally write down on a piece of paper for this sort of session, but I'd honestly like to give it a go.

</div>
[Eduardo Bouças - AI and the creator's funnel](https://eduardoboucas.com/posts/2025-04-07-ai-creators-funnel/)

<div class="ml-[calc(1*1rem)] mb-8">
> Software generated entirely by AI is not an hypothetical future — it's [a reality today](https://arstechnica.com/ai/2024/10/google-ceo-says-over-25-of-new-google-code-is-generated-by-ai/). I don't think it's an overstatement to say that this is the largest shift in the history of this industry, unravelling before our eyes at an astonishing pace.
>
> [...]
>
> I take joy from different aspects of writing code on a daily basis: writing some tests and seeing them pass for the first time, dissecting the root cause of a gnarly bug, or coming up with an elegant solution for a seemingly impossible problem (and always patting myself on the back for it).
>
> The realisation that computers can now perform these tasks in a fraction of the time it takes me is unsettling. It's impossible not to ask: will AI replace me?
>
> [...]
>
> As I let those feelings simmer, I wanted to take a step back and look at software as more than just something that I enjoy creating; it can also be a force for good with a profound impact on people’s lives.

Coming to the terms with the state and direction of the software development industry has not been easy, I both agree with and relate with what Eduardo is saying here, it sucks that the art of unassisted programming might become more and more a thing required for only the most bespoke of code, or just for _fun_.

> <Image src='/asset/creators-funnel_1744085355466_0.png' alt='creators-funnel.png' width={360} height={293} /> 
>
> This means that the amazing projects we see today don't represent all the creators, the ideas, or the potential out there — they're just the ones that made it through the creator's funnel. A classic case of [survivorship bias](https://en.wikipedia.org/wiki/Survivorship_bias).

There's [some discussion on Twitter](https://x.com/ID_AA_Carmack/status/1909311174845329874) regarding that Quake II AI demo [mentioned yesterday](/linkblog/2025/04/06), with John Carmack himself chiming in calling it "impressive research work!".

This is honestly close to my current interests, as I'm looking into taking Quake II and turning it into something transformative / _fun_, and doing it by the seemingly "old fashioned" programming approach.

So yeah, my reaction to the thing yesterday, was simply, "Ew!".

But, after considering Edurado's post, I'm _less_ jaded about it, I do think its not super useful to gatekeep the ability to make games, it is an _endeavour_ to learn all the component parts required to make a game.

But also... a one-shot prompt to produce something...

I don't really feel like that is creation still, similar to the current space of generative imagery, purely generative _games_ don't rub me the right way.

Carmack did mention _impressive research work_, and I think generative games are also interesting research work, but I _also_ know as soon as they are _somewhat_ good, they will be packaged up into a consumer product and could even negatively affect the indie space.

I'm conflicted.

Anyways.

</div>
[THE PHOENICIAN SCHEME, a film by Wes Anderson.](https://www.youtube.com/watch?v=GEuMnPl2WI4)

<div class="ml-[calc(1*1rem)] mb-8">
<iframe
    class="my-2"
    width="100%"
    height="400"
    src="https://www.youtube.com/embed/GEuMnPl2WI4"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen
></iframe>

New Wes Anderson movie is a Wes Anderson movie.

As always, great trailer, so many faces, I will be seeing this in theaters.

</div>
[@tobi - Reflexive AI usage is now a baseline expectation at Shopify](https://x.com/tobi/status/1909251946235437514)

<div class="ml-[calc(1*1rem)] mb-8">
Tobi posted an internal memo at Shopify that he assumed would leak, so he himself posted it to Twitter.

I feel like I agree with _aspects_ of this, with regards to integrating AI into workflows, having it codified at the _employee review_ level seems... interesting, but I think for the type of company Shopify is, I get it.

<div class="ml-[calc(2*1rem)] mb-8">
I must say though, the folks that work on the [Ruby YJIT](https://shopify.engineering/ruby-yjit-is-production-ready), or the [Static Typing system](https://shopify.engineering/static-typing-ruby), not sure how happy they will be, but this is probably a extremely small portion of clever people within a larger org where most are fullstack andy's would be my assumption.

</div>
This point didn't feel great though:

> Before asking for more Headcount and resources, teams must demonstrate why they cannot get what they want done using AI. What would this area look like if autonomous AI agents were already part of the team? This question can lead to really fun discussions and projects.

I get what this is saying, but this reads to me like: we're going to hire less people to do software because AI can do the work of more people.

Just feels like the productivity curve of an individual contributor will be going up with a smaller workforce.

I do think being transparent about this is better than having an internal memo that leaks though, but I assume Tobi is the type to do this to mostly boast to other CEOs in the space than actually start a conversation about anything.

</div>
[Rich Trouton - rsync replaced with openrsync on macOS Sequoia](https://derflounder.wordpress.com/2025/04/06/rsync-replaced-with-openrsync-on-macos-sequoia/)

<div class="ml-[calc(1*1rem)] mb-8">
> The **rsync** command line tool has long been included on macOS, but Apple has provided the last version of **rsync** 2.x ([rsync 2.6.9, released in November 2006](https://download.samba.org/pub/rsync/NEWS#2.6.9)) and did not update **rsync** past that even though **rsync** 3.x was released.
>
> [...]
>
> Now with macOS Sequoia, Apple has replaced **rsync** 2.6.9 with [openrsync](https://man.openbsd.org/openrsync), an implementation of **rsync** which is not using any version of the GPL open source license. Instead, **openrsync** is licensed under the [BSD family of licenses](https://en.wikipedia.org/wiki/BSD_licenses), specifically the [ISC license](https://en.wikipedia.org/wiki/ISC_license).

Intersting, MacOS rsync is now using [OpenBSD's openrsync](https://man.openbsd.org/openrsync.1).

</div>
